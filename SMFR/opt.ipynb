{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd03f41-b034-4c5a-8df9-8848b8fc72cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mSyntaxError: invalid syntax. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from gpflow.kernels import Matern32\n",
    "from gpflow.models import GPR\n",
    "from gpflow import set_trainable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import vectorbt as vbt\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "def fetch_and_process_data(ticker, start_date=\"2024-01-01\", end_date=\"2024-12-31\", train_ratio=0.8):\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if data.empty or \"Adj Close\" not in data:\n",
    "            raise ValueError(f\"No valid data found for {ticker}\")\n",
    "        \n",
    "        close = data[\"Adj Close\"]\n",
    "        split_index = int(len(close) * train_ratio)\n",
    "        \n",
    "        price_scale = 1000 if close.mean() < 0.1 else 1\n",
    "        scaled_close = close * price_scale\n",
    "        \n",
    "        # Use percentage returns if price is high enough, else use log returns\n",
    "        returns = scaled_close.pct_change().dropna() if close.mean() > 0.1 else np.log(scaled_close / scaled_close.shift(1)).dropna()\n",
    "        \n",
    "        train_returns = returns.iloc[:split_index]\n",
    "        test_returns = returns.iloc[split_index:]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_returns.values.reshape(-1, 1))\n",
    "        \n",
    "        train_std = scaler.transform(train_returns.values.reshape(-1, 1))\n",
    "        test_std = scaler.transform(test_returns.values.reshape(-1, 1))\n",
    "        \n",
    "        std_returns = np.concatenate([train_std, test_std]).flatten()\n",
    "        \n",
    "        return close[returns.index], pd.Series(std_returns, index=returns.index), split_index\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error processing {ticker}: {str(e)}\")\n",
    "\n",
    "def generate_signals(returns, split_index, epochs=50):\n",
    "    X = np.arange(len(returns), dtype=np.float64).reshape(-1, 1)\n",
    "    y = returns.values.reshape(-1, 1)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    kernel = Matern32()\n",
    "    gpr = GPR(data=(X_train, y_train), kernel=kernel)\n",
    "    set_trainable(gpr.likelihood.variance, False)\n",
    "    \n",
    "    trend_train = gpr.predict_f(X_train)[0].numpy().flatten()\n",
    "    trend_test = gpr.predict_f(X_test)[0].numpy().flatten()\n",
    "    trend = np.concatenate([trend_train, trend_test])\n",
    "    \n",
    "    # Combine original returns and trend as features\n",
    "    features = np.hstack([returns.values.reshape(-1, 1), trend.reshape(-1, 1)])\n",
    "    train_features = features[:split_index]\n",
    "    train_labels = y[:split_index].flatten()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(1, 2)),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dense(1, activation=\"tanh\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "    model.fit(\n",
    "        train_features.reshape((train_features.shape[0], 1, train_features.shape[1])),\n",
    "        train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    all_features = features.reshape((features.shape[0], 1, features.shape[1]))\n",
    "    predicted_signals = model.predict(all_features).flatten()\n",
    "    # Clip the output to be between -1 and 1\n",
    "    return np.clip(predicted_signals, -1, 1)\n",
    "\n",
    "def backtest_strategy(close, positions, entry_threshold=0.2, exit_threshold=-0.2):\n",
    "    # signals will be True if the positions exceed (or undercut) the thresholds\n",
    "    entries = positions > entry_threshold\n",
    "    exits = positions < exit_threshold\n",
    "    \n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=close,\n",
    "        entries=entries,\n",
    "        exits=exits,\n",
    "        size=np.abs(positions),\n",
    "        freq=\"1D\"\n",
    "    )\n",
    "    return pf\n",
    "\n",
    "def optimize_parameters(ticker=\"BTC-USD\"):\n",
    "    # Define candidate parameters for grid search\n",
    "    epochs_list = [30, 50, 70]\n",
    "    entry_thresholds = [0.15, 0.2, 0.25]\n",
    "    exit_thresholds = [-0.15, -0.2, -0.25]\n",
    "    \n",
    "    best_config = None\n",
    "    best_return = -np.inf\n",
    "    results = []\n",
    "    \n",
    "    close, returns, split_index = fetch_and_process_data(ticker)\n",
    "    \n",
    "    for epochs in epochs_list:\n",
    "        # Use the same signals generation method but vary the LSTM training epochs\n",
    "        positions = generate_signals(returns, split_index, epochs=epochs)\n",
    "        for entry_thresh in entry_thresholds:\n",
    "            for exit_thresh in exit_thresholds:\n",
    "                # Backtest with current parameters\n",
    "                pf = backtest_strategy(close, positions,\n",
    "                                        entry_threshold=entry_thresh,\n",
    "                                        exit_threshold=exit_thresh)\n",
    "                tot_ret = pf.total_return()\n",
    "                sharpe = pf.sharpe_ratio()\n",
    "                max_dd = pf.max_drawdown()\n",
    "                config = {\n",
    "                    'epochs': epochs,\n",
    "                    'entry_threshold': entry_thresh,\n",
    "                    'exit_threshold': exit_thresh,\n",
    "                    'Total Return': tot_ret,\n",
    "                    'Sharpe Ratio': sharpe,\n",
    "                    'Max Drawdown': max_dd\n",
    "                }\n",
    "                results.append(config)\n",
    "                \n",
    "                if tot_ret > best_return:\n",
    "                    best_return = tot_ret\n",
    "                    best_config = config\n",
    "                    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Grid Search Results:\")\n",
    "    print(results_df.to_markdown(index=False))\n",
    "    \n",
    "    print(\"\\nBest Configuration:\")\n",
    "    print(best_config)\n",
    "    return best_config\n",
    "\n",
    "def main():\n",
    "    ticker = \"BTC-USD\"\n",
    "    print(f\"\\nBacktesting {ticker} with default parameters...\")\n",
    "    try:\n",
    "        close, returns, split_index = fetch_and_process_data(ticker)\n",
    "        positions = generate_signals(returns, split_index, epochs=50)\n",
    "        portfolio = backtest_strategy(close, positions)\n",
    "        \n",
    "\t\t\n",
    "        print(f\"Total Return: {portfolio.total_return():.2%}\")\n",
    "        print(f\"Sharpe Ratio: {portfolio.sharpe_ratio():.2f}\")\n",
    "        print(f\"Max Drawdown: {portfolio.max_drawdown():.2%}\")\n",
    "        \n",
    "        print(\"\\nStarting parameter optimization...\")\n",
    "        best_config = optimize_parameters(ticker)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in backtesting {ticker}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mSyntaxError: invalid syntax. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mSyntaxError: invalid syntax. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from gpflow.kernels import Matern32\n",
    "from gpflow.models import GPR\n",
    "from gpflow import set_trainable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import vectorbt as vbt\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "def fetch_and_process_data(ticker, start_date=\"2024-01-01\", end_date=\"2024-12-31\", train_ratio=0.8):\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if data.empty or \"Adj Close\" not in data:\n",
    "            raise ValueError(f\"No valid data found for {ticker}\")\n",
    "        \n",
    "        close = data[\"Adj Close\"]\n",
    "        split_index = int(len(close) * train_ratio)\n",
    "        \n",
    "        price_scale = 1000 if close.mean() < 0.1 else 1\n",
    "        scaled_close = close * price_scale\n",
    "        \n",
    "        # Use percentage returns if price is high enough, else use log returns\n",
    "        returns = scaled_close.pct_change().dropna() if close.mean() > 0.1 else np.log(scaled_close / scaled_close.shift(1)).dropna()\n",
    "        \n",
    "        train_returns = returns.iloc[:split_index]\n",
    "        test_returns = returns.iloc[split_index:]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_returns.values.reshape(-1, 1))\n",
    "        \n",
    "        train_std = scaler.transform(train_returns.values.reshape(-1, 1))\n",
    "        test_std = scaler.transform(test_returns.values.reshape(-1, 1))\n",
    "        \n",
    "        std_returns = np.concatenate([train_std, test_std]).flatten()\n",
    "        \n",
    "        return close[returns.index], pd.Series(std_returns, index=returns.index), split_index\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error processing {ticker}: {str(e)}\")\n",
    "\n",
    "def backtest_strategy(close, positions, entry_threshold=0.2, exit_threshold=-0.2):\n",
    "    # Use thresholds to decide entries and exits\n",
    "    entries = positions > entry_threshold\n",
    "    exits = positions < exit_threshold\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=close,\n",
    "        entries=entries,\n",
    "        exits=exits,\n",
    "        size=np.abs(positions),\n",
    "        freq=\"1D\"\n",
    "    )\n",
    "    return pf\n",
    "\n",
    "# Strategy signal generators\n",
    "\n",
    "def generate_signals_long_only(close, **kwargs):\n",
    "    # A simple long-only strategy: go long when the price increases day-over-day\n",
    "    signals = np.where(close.diff().fillna(0) > 0, 1, 0)\n",
    "    return signals.astype(np.float64)\n",
    "\n",
    "def generate_signals_macd(close, **kwargs):\n",
    "    # Simple MACD: difference between two exponential moving averages\n",
    "    ema12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema26 = close.ewm(span=26, adjust=False).mean()\n",
    "    macd = ema12 - ema26\n",
    "    # Normalize MACD signal to be between -1 and 1 using a tanh transformation\n",
    "    signals = np.tanh(macd)\n",
    "    return signals\n",
    "\n",
    "def generate_signals_tsmom(returns, w=0, **kwargs):\n",
    "    # TSMOM: combine returns with a weight parameter w\n",
    "    # For demonstration, simply scale the returns by a weight and clip to [-1, 1]\n",
    "    signals = np.tanh(w * returns.values)\n",
    "    return signals\n",
    "\n",
    "def generate_signals_lstm_cpd(returns, split_index, lbw=21, epochs=50, **kwargs):\n",
    "    # LSTM with CPD flavor using a lookback window (lbw).\n",
    "    # Create a second feature as the moving average computed over the lookback window.\n",
    "    ma_feature = returns.rolling(window=lbw, min_periods=1).mean().values\n",
    "    features = np.column_stack((returns.values, ma_feature))\n",
    "    \n",
    "    X = np.arange(len(returns), dtype=np.float64).reshape(-1, 1)\n",
    "    y = returns.values.reshape(-1, 1)\n",
    "    \n",
    "    # Split features\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    train_features = features[:split_index]\n",
    "    train_labels = y[:split_index].flatten()\n",
    "    \n",
    "    # Reshape features for LSTM input\n",
    "    train_features = train_features.reshape((train_features.shape[0], 1, train_features.shape[1]))\n",
    "    all_features = features.reshape((features.shape[0], 1, features.shape[1]))\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(1, 2)),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dense(1, activation=\"tanh\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "    model.fit(train_features, train_labels, epochs=epochs, batch_size=32, verbose=0)\n",
    "    \n",
    "    predicted_signals = model.predict(all_features).flatten()\n",
    "    return np.clip(predicted_signals, -1, 1)\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def optimize_all_strategies(ticker=\"BTC-USD\"):\n",
    "    # Define grids for each strategy\n",
    "    strategies = {\n",
    "        \"Long Only\": {\n",
    "            \"generator\": generate_signals_long_only,\n",
    "            \"params_grid\": [{}]  \n",
    "        },\n",
    "        \"MACD\": {\n",
    "            \"generator\": generate_signals_macd,\n",
    "            \"params_grid\": [{}]\n",
    "        },\n",
    "        \"TSMOM\": {\n",
    "            \"generator\": generate_signals_tsmom,\n",
    "            \"params_grid\": [{'w': w} for w in [0, 0.5, 1]]\n",
    "        },\n",
    "        \"LSTM w/ CPD\": {\n",
    "            \"generator\": generate_signals_lstm_cpd,\n",
    "            \"params_grid\": [ {'lbw': lbw, 'epochs': 50} for lbw in [10, 21, 63, 126, 252] ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Grid for backtest thresholds\n",
    "    entry_thresholds = [0.15, 0.2, 0.25]\n",
    "    exit_thresholds = [-0.15, -0.2, -0.25]\n",
    "    \n",
    "    close, returns, split_index = fetch_and_process_data(ticker)\n",
    "    best_results = []\n",
    "    \n",
    "    for strat_name, strat_info in strategies.items():\n",
    "        best_config = None\n",
    "        best_return = -np.inf\n",
    "        results = []\n",
    "        print(f\"\\nOptimizing strategy: {strat_name}\")\n",
    "        \n",
    "        for params in strat_info[\"params_grid\"]:\n",
    "            # Generate signals based on strategy\n",
    "            if strat_name == \"LSTM w/ CPD\":\n",
    "                # LSTM based strategy needs split_index\n",
    "                signals = strat_info[\"generator\"](returns, split_index, **params)\n",
    "            else:\n",
    "                signals = strat_info[\"generator\"](close if strat_name in [\"Long Only\", \"MACD\"] else returns, **params)\n",
    "            \n",
    "            for et, xt in product(entry_thresholds, exit_thresholds):\n",
    "                pf = backtest_strategy(close, signals, entry_threshold=et, exit_threshold=xt)\n",
    "                tot_ret = pf.total_return()\n",
    "                sharpe = pf.sharpe_ratio()\n",
    "                max_dd = pf.max_drawdown()\n",
    "                config = {\n",
    "                    'Strategy': strat_name,\n",
    "                    **params,\n",
    "                    'entry_threshold': et,\n",
    "                    'exit_threshold': xt,\n",
    "                    'Total Return': tot_ret,\n",
    "                    'Sharpe Ratio': sharpe,\n",
    "                    'Max Drawdown': max_dd\n",
    "                }\n",
    "                results.append(config)\n",
    "                if tot_ret > best_return:\n",
    "                    best_return = tot_ret\n",
    "                    best_config = config\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(f\"\\n{strat_name} Grid Search Results:\")\n",
    "        print(results_df.to_markdown(index=False))\n",
    "        print(f\"\\nBest {strat_name} Configuration:\")\n",
    "        print(best_config)\n",
    "        best_results.append(best_config)\n",
    "    \n",
    "    best_overall = sorted(best_results, key=lambda x: x['Total Return'], reverse=True)[0]\n",
    "    print(\"\\nBest Overall Strategy:\", best_overall['Strategy'])\n",
    "    print(best_overall)\n",
    "    return best_results\n",
    "\n",
    "def main():\n",
    "    ticker = \"BTC-USD\"\n",
    "    print(f\"\\nBacktesting {ticker} with multi-strategy optimization...\")\n",
    "    try:\n",
    "        optimize_all_strategies(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in optimization: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
